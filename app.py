import yfinance as yf
import pandas as pd
import numpy as np
from lightgbm import LGBMClassifier
from sklearn.model_selection import train_test_split, TimeSeriesSplit
from sklearn.metrics import f1_score, accuracy_score # –î–æ–±–∞–≤–ª–µ–Ω–∞ f1_score
from sklearn.preprocessing import StandardScaler
import joblib
import os
import json
from fastapi import FastAPI
import uvicorn
from datetime import datetime, timedelta
# from send_telegram import send_telegram_message # –ó–∞–∫–æ–º–º–µ–Ω—Ç–∏—Ä–æ–≤–∞–Ω–æ, —Ç–∞–∫ –∫–∞–∫ send_telegram_message –Ω–µ –ø—Ä–µ–¥–æ—Å—Ç–∞–≤–ª–µ–Ω
import time
import optuna
import logging # –ò–º–ø–æ—Ä—Ç –º–æ–¥—É–ª—è –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è

# –ò–º–ø–æ—Ä—Ç –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏
import config

# --- –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è ---
logging.basicConfig(level=config.LOG_LEVEL, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

app = FastAPI()

# --- –ö–æ–Ω—Å—Ç–∞–Ω—Ç—ã –∏–∑ config.py ---
MODEL_PATH = config.MODEL_PATH
ACCURACY_PATH = config.ACCURACY_PATH
HORIZON_PERIODS = config.HORIZON_PERIODS
LOOKBACK_PERIOD = config.LOOKBACK_PERIOD
MIN_DATA_ROWS = config.MIN_DATA_ROWS
TARGET_ACCURACY = config.TARGET_ACCURACY
MIN_ACCURACY_FOR_SIGNAL = config.MIN_ACCURACY_FOR_SIGNAL
MAX_TRAINING_TIME = config.MAX_TRAINING_TIME
PREDICTION_PROB_THRESHOLD = config.PREDICTION_PROB_THRESHOLD
N_SPLITS_TS_CV = config.N_SPLITS_TS_CV

# –ó–∞–≥–ª—É—à–∫–∞ –¥–ª—è send_telegram_message, –µ—Å–ª–∏ –æ–Ω–∞ –Ω–µ –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∞
def send_telegram_message(message):
    logger.info(f"Telegram message (mock): {message}")

def compute_rsi(data, periods=14):
    delta = data.diff()
    gain = delta.where(delta > 0, 0).rolling(window=periods).mean()
    loss = -delta.where(delta < 0, 0).rolling(window=periods).mean()
    rs = gain / (loss + 1e-10)
    rsi = 100 - (100 / (1 + rs))
    return rsi

def compute_bollinger_bands(data, window=20, num_std=2):
    ma = data.rolling(window=window).mean()
    std = data.rolling(window=window).std()
    upper = ma + (num_std * std)
    lower = ma - (num_std * std)
    return upper, lower

def compute_macd(data, fast=12, slow=26, signal=9):
    exp1 = data.ewm(span=fast, adjust=False).mean()
    exp2 = data.ewm(span=slow, adjust=False).mean()
    macd = exp1 - exp2
    signal_line = macd.ewm(span=signal, adjust=False).mean()
    return macd, signal_line

def prepare_data():
    logger.info("Downloading data...")
    try:
        end_date = datetime.now()
        while end_date.weekday() >= 5: # –ü—Ä–æ–ø—É—Å–∫–∞–µ–º –≤—ã—Ö–æ–¥–Ω—ã–µ
            end_date -= timedelta(days=1)
        # –ò—Å–ø–æ–ª—å–∑—É–µ–º LOOKBACK_PERIOD –∏–∑ config.py
        df = yf.download("EURUSD=X", interval="1d", period=LOOKBACK_PERIOD, end=end_date)
    except Exception as e:
        logger.error(f"Error downloading data: {str(e)}")
        raise ValueError(f"Error downloading data: {str(e)}")

    if df.empty:
        logger.error("Empty data received from Yahoo Finance.")
        raise ValueError("Empty data received from Yahoo Finance.")

    logger.info(f"Downloaded {len(df)} rows, from {df.index[0]} to {df.index[-1]}")
    
    if isinstance(df.columns, pd.MultiIndex):
        df.columns = [col[0] for col in df.columns]

    df = df[(df['Close'] > 0) & (df['Open'] > 0)]
    logger.info(f"After filtering Open/Close > 0: {len(df)} rows")

    df['Close'] = df['Close'].fillna(method='ffill').fillna(method='bfill')
    df['Target'] = df['Close'].shift(-HORIZON_PERIODS)

    if df['Target'].isna().all():
        logger.error("Target column contains only NaNs.")
        raise ValueError("Target column contains only NaNs.")

    df['RSI'] = compute_rsi(df['Close'])
    df['MA20'] = df['Close'].rolling(window=20).mean()
    df['BB_Up'], df['BB_Low'] = compute_bollinger_bands(df['Close'])
    df['Lag1'] = df['Close'].shift(1)
    df['MACD'], df['MACD_Sig'] = compute_macd(df['Close'])
    df['Hour'] = df.index.hour
    df['DayOfWeek'] = df.index.dayofweek
    df['PriceChange'] = df['Close'].pct_change()
    # –í–Ω–∏–º–∞–Ω–∏–µ: —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏—è —ç–∫—Å—Ç—Ä–µ–º–∞–ª—å–Ω—ã—Ö –∏–∑–º–µ–Ω–µ–Ω–∏–π —Ü–µ–Ω –º–æ–∂–µ—Ç –æ—Ç–±—Ä–æ—Å–∏—Ç—å –≤–∞–∂–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ.
    # –ò—Å–ø–æ–ª—å–∑—É–π—Ç–µ –æ—Å—Ç–æ—Ä–æ–∂–Ω–æ –∏ –ø—Ä–æ–≤–µ—Ä—å—Ç–µ –≤–ª–∏—è–Ω–∏–µ –Ω–∞ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å.
    df = df[df['PriceChange'].abs() < 0.1] 

    initial_rows = len(df)
    # dropna() —É–¥–∞–ª—è–µ—Ç —Å—Ç—Ä–æ–∫–∏, –≥–¥–µ –∏–Ω–¥–∏–∫–∞—Ç–æ—Ä—ã –Ω–µ –º–æ–≥–ª–∏ –±—ã—Ç—å —Ä–∞—Å—Å—á–∏—Ç–∞–Ω—ã –∏–∑-–∑–∞ –Ω–µ–¥–æ—Å—Ç–∞—Ç–∫–∞ –¥–∞–Ω–Ω—ã—Ö
    # –∏–ª–∏ –≥–¥–µ –±—ã–ª–∏ NaN –≤ –∏—Å—Ö–æ–¥–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö.
    df = df.dropna() 
    logger.info(f"After dropna: {len(df)} rows (dropped {initial_rows - len(df)})")

    if len(df) < MIN_DATA_ROWS:
        logger.error(f"Insufficient data: {len(df)} rows, required {MIN_DATA_ROWS}")
        raise ValueError(f"Insufficient data: {len(df)} rows, required {MIN_DATA_ROWS}")

    X = df[['Open', 'High', 'Low', 'Close', 'RSI', 'MA20', 'BB_Up', 'BB_Low',
            'Lag1', 'MACD', 'MACD_Sig', 'Hour', 'DayOfWeek']]
    y = (df['Target'] > df['Close']).astype(int) # 1 for BUY, 0 for SELL/HOLD

    X = X.replace([np.inf, -np.inf], np.nan).fillna(method='ffill').fillna(method='bfill')

    scaler = StandardScaler()
    X_scaled = scaler.fit_transform(X)
    X = pd.DataFrame(X_scaled, columns=X.columns, index=X.index)

    logger.info(f"X shape: {X.shape}, y distribution: {y.value_counts().to_dict()}")
    return X, y, scaler

def train_model():
    try:
        X, y, scaler = prepare_data()
    except Exception as e:
        logger.error(f"Data preparation error, cannot train model: {e}")
        return

    # –†–∞–∑–¥–µ–ª–µ–Ω–∏–µ –Ω–∞ –æ–±—É—á–∞—é—â—É—é/–≤–∞–ª–∏–¥–∞—Ü–∏–æ–Ω–Ω—É—é (–¥–ª—è Optuna) –∏ —Ç–µ—Å—Ç–æ–≤—É—é (–¥–ª—è —Ñ–∏–Ω–∞–ª—å–Ω–æ–π –æ—Ü–µ–Ω–∫–∏) –≤—ã–±–æ—Ä–∫–∏
    # –¢–µ—Å—Ç–æ–≤–∞—è –≤—ã–±–æ—Ä–∫–∞ - –ø–æ—Å–ª–µ–¥–Ω–∏–µ 20% –¥–∞–Ω–Ω—ã—Ö
    X_train_val, X_test, y_train_val, y_test = train_test_split(X, y, test_size=0.2, shuffle=False)
    
    logger.info(f"Train/Validation set size: {len(X_train_val)}, Test set size: {len(X_test)}")

    def objective(trial):
        params = {
            'n_estimators': trial.suggest_int('n_estimators', 50, 150),
            'max_depth': trial.suggest_int('max_depth', 3, 10),
            'learning_rate': trial.suggest_float('learning_rate', 0.01, 0.1),
            'subsample': trial.suggest_float('subsample', 0.6, 1.0),
            'min_child_samples': trial.suggest_int('min_child_samples', 10, 50),
            'min_gain_to_split': trial.suggest_float('min_gain_to_split', 0.0, 0.1),
            'random_state': 42,
            'force_col_wise': True,
            'verbose': -1,
        }

        model = LGBMClassifier(**params)
        
        # Time Series Cross-Validation –¥–ª—è –æ—Ü–µ–Ω–∫–∏ –≥–∏–ø–µ—Ä–ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤
        tscv = TimeSeriesSplit(n_splits=N_SPLITS_TS_CV)
        f1_scores = []

        for train_index, val_index in tscv.split(X_train_val):
            X_fold_train, X_fold_val = X_train_val.iloc[train_index], X_train_val.iloc[val_index]
            y_fold_train, y_fold_val = y_train_val.iloc[train_index], y_train_val.iloc[val_index]

            model.fit(X_fold_train, y_fold_train)
            preds = model.predict(X_fold_val)
            f1_scores.append(f1_score(y_fold_val, preds)) # –ò—Å–ø–æ–ª—å–∑—É–µ–º f1_score

        avg_f1 = np.mean(f1_scores)
        
        # –î–æ–±–∞–≤–ª—è–µ–º –æ—Ç—á–µ—Ç–Ω–æ—Å—Ç—å –¥–ª—è –ø—Ä—É–Ω–µ—Ä–∞
        trial.report(avg_f1, trial.number)
        if trial.should_prune():
            raise optuna.exceptions.TrialPruned()

        return avg_f1

    logger.info("üîç Starting Optuna hyperparameter search...")
    study = optuna.create_study(direction="maximize", pruner=optuna.pruners.HyperbandPruner())
    study.optimize(objective, timeout=MAX_TRAINING_TIME)

    best_params = study.best_params
    best_f1_score = study.best_value # –¢–µ–ø–µ—Ä—å —ç—Ç–æ F1-score

    logger.info(f"‚úÖ Optuna best F1-score: {best_f1_score:.4f}")
    logger.info(f"üìã Best params: {best_params}")

    if best_f1_score < MIN_ACCURACY_FOR_SIGNAL: # –ò—Å–ø–æ–ª—å–∑—É–µ–º F1-score –¥–ª—è –ø–æ—Ä–æ–≥–∞
        logger.warning(f"‚ùå F1-score {best_f1_score:.2f} too low. No model saved.")
        return

    # –û–±—É—á–∞–µ–º —Ñ–∏–Ω–∞–ª—å–Ω—É—é –º–æ–¥–µ–ª—å –Ω–∞ –≤—Å–µ–π –æ–±—É—á–∞—é—â–µ–π/–≤–∞–ª–∏–¥–∞—Ü–∏–æ–Ω–Ω–æ–π –≤—ã–±–æ—Ä–∫–µ —Å –ª—É—á—à–∏–º–∏ –ø–∞—Ä–∞–º–µ—Ç—Ä–∞–º–∏
    best_model = LGBMClassifier(**best_params, random_state=42, force_col_wise=True, verbose=-1)
    best_model.fit(X_train_val, y_train_val)

    # –û—Ü–µ–Ω–∏–≤–∞–µ–º —Ñ–∏–Ω–∞–ª—å–Ω—É—é –º–æ–¥–µ–ª—å –Ω–∞ —Ç–µ—Å—Ç–æ–≤–æ–π –≤—ã–±–æ—Ä–∫–µ
    test_preds = best_model.predict(X_test)
    final_accuracy = accuracy_score(y_test, test_preds) # –ú–æ–∂–Ω–æ –æ—Å—Ç–∞–≤–∏—Ç—å accuracy –¥–ª—è –æ–±—â–µ–π –æ—Ü–µ–Ω–∫–∏
    final_f1_score = f1_score(y_test, test_preds)
    logger.info(f"Final model performance on TEST set: Accuracy={final_accuracy:.4f}, F1-score={final_f1_score:.4f}")

    joblib.dump({'model': best_model, 'scaler': scaler}, MODEL_PATH)
    with open(ACCURACY_PATH, "w") as f:
        json.dump({
            "accuracy": final_accuracy, # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Ñ–∏–Ω–∞–ª—å–Ω—É—é —Ç–æ—á–Ω–æ—Å—Ç—å –Ω–∞ —Ç–µ—Å—Ç–æ–≤–æ–π –≤—ã–±–æ—Ä–∫–µ
            "f1_score": final_f1_score, # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Ñ–∏–Ω–∞–ª—å–Ω—ã–π F1-score –Ω–∞ —Ç–µ—Å—Ç–æ–≤–æ–π –≤—ã–±–æ—Ä–∫–µ
            "last_trained": str(datetime.now()),
            "best_params": best_params
        }, f)

    # –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º —Å–∏–≥–Ω–∞–ª –Ω–∞ –æ—Å–Ω–æ–≤–µ –ø–æ—Å–ª–µ–¥–Ω–µ–π –¥–æ—Å—Ç—É–ø–Ω–æ–π —Ç–æ—á–∫–∏ –¥–∞–Ω–Ω—ã—Ö
    if not X.empty:
        generate_signal(best_model, scaler, X.iloc[-1:], X.index[-1])
    else:
        logger.warning("No data to generate signal after training.")

def generate_signal(model, scaler, latest_data, last_index):
    try:
        if latest_data.empty:
            logger.warning("No latest data to generate signal.")
            return

        latest_data_scaled = scaler.transform(latest_data)
        latest_data_scaled = pd.DataFrame(latest_data_scaled, columns=latest_data.columns, index=latest_data.index)
        
        # –ü–æ–ª—É—á–∞–µ–º –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç–∏ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è
        prediction_proba = model.predict_proba(latest_data_scaled)[0]
        
        # –û–ø—Ä–µ–¥–µ–ª—è–µ–º —Å–∏–≥–Ω–∞–ª –Ω–∞ –æ—Å–Ω–æ–≤–µ –ø–æ—Ä–æ–≥–∞ –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç–∏
        signal_type = "HOLD"
        current_price = latest_data['Close'].iloc[0]
        stop_loss = None
        take_profit = None

        if prediction_proba[1] >= PREDICTION_PROB_THRESHOLD: # –í–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç—å –∫–ª–∞—Å—Å–∞ 1 (BUY)
            signal_type = "BUY"
            stop_loss = current_price * 0.99 # –ü—Ä–∏–º–µ—Ä: 1% –Ω–∏–∂–µ
            take_profit = current_price * 1.015 # –ü—Ä–∏–º–µ—Ä: 1.5% –≤—ã—à–µ
        elif prediction_proba[0] >= PREDICTION_PROB_THRESHOLD: # –í–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç—å –∫–ª–∞—Å—Å–∞ 0 (SELL)
            signal_type = "SELL"
            stop_loss = current_price * 1.01 # –ü—Ä–∏–º–µ—Ä: 1% –≤—ã—à–µ
            take_profit = current_price * 0.985 # –ü—Ä–∏–º–µ—Ä: 1.5% –Ω–∏–∂–µ
        
        # –ö–æ–º–º–µ–Ω—Ç–∞—Ä–∏–π: –§–∏–∫—Å–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ SL/TP –º–æ–≥—É—Ç –±—ã—Ç—å –Ω–µ–æ–ø—Ç–∏–º–∞–ª—å–Ω—ã–º–∏.
        # –†–∞—Å—Å–º–æ—Ç—Ä–∏—Ç–µ –¥–∏–Ω–∞–º–∏—á–µ—Å–∫–∏–π —Ä–∞—Å—á–µ—Ç –Ω–∞ –æ—Å–Ω–æ–≤–µ –≤–æ–ª–∞—Ç–∏–ª—å–Ω–æ—Å—Ç–∏ (–Ω–∞–ø—Ä–∏–º–µ—Ä, ATR).

        signal = {
            "time": str(datetime.now()),
            "price": round(current_price, 5),
            "signal": signal_type,
            "buy_proba": round(prediction_proba[1], 4),
            "sell_proba": round(prediction_proba[0], 4),
            "stop_loss": round(stop_loss, 5) if stop_loss else "N/A",
            "take_profit": round(take_profit, 5) if take_profit else "N/A",
        }

        msg = (
            f"üìä Signal: {signal['signal']}\n"
            f"üïí Time: {signal['time']}\n"
            f"üí∞ Price: {signal['price']}\n"
            f"‚¨ÜÔ∏è Buy Proba: {signal['buy_proba']}\n"
            f"‚¨áÔ∏è Sell Proba: {signal['sell_proba']}\n"
            f"üìâ Stop Loss: {signal['stop_loss']}\n"
            f"üìà Take Profit: {signal['take_profit']}"
        )
        logger.info(f"Signal generated:\n{msg}")
        send_telegram_message(msg)
    except Exception as e:
        logger.error(f"Signal generation error: {e}")

@app.get("/")
async def root():
    if not os.path.exists(MODEL_PATH) or not os.path.exists(ACCURACY_PATH):
        logger.info("Model or accuracy file not found. Training new model.")
        train_model()
    else:
        with open(ACCURACY_PATH, "r") as f:
            data = json.load(f)
        last_trained = datetime.fromisoformat(data["last_trained"])
        
        # –ò—Å–ø–æ–ª—å–∑—É–µ–º F1-score –¥–ª—è –ø—Ä–æ–≤–µ—Ä–∫–∏ –Ω–µ–æ–±—Ö–æ–¥–∏–º–æ—Å—Ç–∏ –ø–µ—Ä–µ–æ–±—É—á–µ–Ω–∏—è, –µ—Å–ª–∏ –æ–Ω –µ—Å—Ç—å
        current_metric = data.get("f1_score", data.get("accuracy", 0.0)) # –ü—Ä–µ–¥–ø–æ—á–∏—Ç–∞–µ–º f1_score
        
        if (datetime.now() - last_trained).days >= 1 or current_metric < TARGET_ACCURACY:
            logger.info(f"Model needs retraining. Last trained: {last_trained}, Metric: {current_metric:.2f}")
            train_model()
        else:
            logger.info(f"Model is up to date. Last trained: {last_trained}, Metric: {current_metric:.2f}")
            try:
                model_data = joblib.load(MODEL_PATH)
                model = model_data['model']
                scaler = model_data['scaler']
                
                end_date = datetime.now()
                while end_date.weekday() >= 5:
                    end_date -= timedelta(days=1)
                # –ó–∞–≥—Ä—É–∂–∞–µ–º –¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –¥–∞–Ω–Ω—ã—Ö –¥–ª—è —Ä–∞—Å—á–µ—Ç–∞ –∏–Ω–¥–∏–∫–∞—Ç–æ—Ä–æ–≤ –¥–ª—è –ø–æ—Å–ª–µ–¥–Ω–µ–π —Ç–æ—á–∫–∏
                df_latest = yf.download("EURUSD=X", interval="1d", period="30d", end=end_date) 
                if isinstance(df_latest.columns, pd.MultiIndex):
                    df_latest.columns = [col[0] for col in df_latest.columns]
                df_latest['Close'] = df_latest['Close'].fillna(method='ffill').fillna(method='bfill')
                
                df_latest['RSI'] = compute_rsi(df_latest['Close'])
                df_latest['MA20'] = df_latest['Close'].rolling(window=20).mean()
                df_latest['BB_Up'], df_latest['BB_Low'] = compute_bollinger_bands(df_latest['Close'])
                df_latest['Lag1'] = df_latest['Close'].shift(1)
                df_latest['MACD'], df_latest['MACD_Sig'] = compute_macd(df_latest['Close'])
                df_latest['Hour'] = df_latest.index.hour
                df_latest['DayOfWeek'] = df_latest.index.dayofweek
                df_latest['PriceChange'] = df_latest['Close'].pct_change()
                df_latest = df_latest[df_latest['PriceChange'].abs() < 0.1]
                df_latest = df_latest.dropna()

                if not df_latest.empty:
                    latest_features = df_latest[['Open', 'High', 'Low', 'Close', 'RSI', 'MA20', 'BB_Up', 'BB_Low',
                                                 'Lag1', 'MACD', 'MACD_Sig', 'Hour', 'DayOfWeek']].iloc[-1:]
                    generate_signal(model, scaler, latest_features, latest_features.index[-1])
                else:
                    logger.warning("Could not get enough latest data to generate signal from existing model.")
            except Exception as e:
                logger.error(f"Error loading model or generating signal from existing model: {e}")

    return {"status": "Bot is running"}

if __name__ == "__main__":
    uvicorn.run(app, host=config.UVICORN_HOST, port=config.UVICORN_PORT)
