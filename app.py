import yfinance as yf
import pandas as pd
import numpy as np
from sklearn.ensemble import RandomForestClassifier
from sklearn.model_selection import train_test_split, GridSearchCV
from sklearn.metrics import accuracy_score
import joblib
import os
import json
from fastapi import FastAPI
import uvicorn
from datetime import datetime, timedelta
from send_telegram import send_telegram_message

app = FastAPI()

MODEL_PATH = "model.pkl"
ACCURACY_PATH = "accuracy.json"

# –ü–∞—Ä–∞–º–µ—Ç—Ä—ã —Å—Ç—Ä–∞—Ç–µ–≥–∏–∏
HORIZON_DAYS = 1  # –ü—Ä–æ–≥–Ω–æ–∑ –Ω–∞ 1 –¥–µ–Ω—å –≤–ø–µ—Ä–µ–¥ (~96 —Å–≤–µ—á–µ–π –ø–æ 15 –º–∏–Ω)
LOOKBACK_PERIOD = "60d"  # –ò—Å—Ç–æ—Ä–∏—è –¥–ª—è –æ–±—É—á–µ–Ω–∏—è ‚Äî 60 –¥–Ω–µ–π
MIN_DATA_ROWS = 100  # –ú–∏–Ω–∏–º–∞–ª—å–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Å—Ç—Ä–æ–∫ –¥–ª—è –æ–±—É—á–µ–Ω–∏—è
TARGET_ACCURACY = 0.8  # –¶–µ–ª–µ–≤–∞—è —Ç–æ—á–Ω–æ—Å—Ç—å
MAX_RETRAIN_ATTEMPTS = 5  # –ú–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –ø–æ–ø—ã—Ç–æ–∫ –ø–µ—Ä–µ—Ç—Ä–µ–Ω–∏—Ä–æ–≤–∫–∏

def prepare_data():
    print("–ó–∞–≥—Ä—É–∑–∫–∞ –¥–∞–Ω–Ω—ã—Ö –∏–∑ Yahoo Finance...")
    try:
        # Set end_date to last Friday to avoid weekend data gaps
        end_date = datetime.now()
        if end_date.weekday() >= 5:  # Saturday (5) or Sunday (6)
            end_date -= timedelta(days=end_date.weekday() - 4)  # Go to last Friday
        df = yf.download("EURUSD=X", interval="15m", period=LOOKBACK_PERIOD, end=end_date)
    except Exception as e:
        raise ValueError(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –∑–∞–≥—Ä—É–∑–∫–µ –¥–∞–Ω–Ω—ã—Ö –∏–∑ Yahoo Finance: {str(e)}")

    if df.empty or len(df) == 0:
        raise ValueError("–î–∞–Ω–Ω—ã–µ –∏–∑ Yahoo Finance –ø—É—Å—Ç—ã –∏–ª–∏ –Ω–µ —Å–æ–¥–µ—Ä–∂–∞—Ç —Å—Ç—Ä–æ–∫.")

    print(f"Downloaded {len(df)} rows.")
    print("Column structure:\n", df.columns)

    # Handle multi-index columns
    if isinstance(df.columns, pd.MultiIndex):
        print("Multi-index columns detected. Flattening to single-level columns.")
        df.columns = [col[0] for col in df.columns]

    required_columns = ['Open', 'High', 'Low', 'Close', 'Volume']
    missing_columns = [col for col in required_columns if col not in df.columns]
    if missing_columns:
        raise ValueError(f"–û—Ç—Å—É—Ç—Å—Ç–≤—É—é—Ç –Ω–µ–æ–±—Ö–æ–¥–∏–º—ã–µ —Å—Ç–æ–ª–±—Ü—ã: {missing_columns}")

    print("Initial data sample:\n", df.head())
    print("Missing values:\n", df.isna().sum())

    if df['Close'].isna().all():
        raise ValueError("–°—Ç–æ–ª–±–µ—Ü 'Close' —Å–æ–¥–µ—Ä–∂–∏—Ç —Ç–æ–ª—å–∫–æ NaN –∑–Ω–∞—á–µ–Ω–∏—è.")
    if df['Close'].isna().any():
        print("Warning: –û–±–Ω–∞—Ä—É–∂–µ–Ω—ã –ø—Ä–æ–ø—É—â–µ–Ω–Ω—ã–µ –∑–Ω–∞—á–µ–Ω–∏—è –≤ —Å—Ç–æ–ª–±—Ü–µ 'Close'. –ó–∞–ø–æ–ª–Ω—è–µ–º –∏—Ö.")
        df['Close'] = df['Close'].fillna(method='ffill').fillna(method='bfill')

    try:
        df['target'] = df['Close'].shift(-int(HORIZON_DAYS * 96))
    except Exception as e:
        raise ValueError(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ —Å–æ–∑–¥–∞–Ω–∏–∏ —Å—Ç–æ–ª–±—Ü–∞ 'target': {str(e)}")

    if 'target' not in df.columns:
        raise ValueError("–ù–µ —É–¥–∞–ª–æ—Å—å —Å–æ–∑–¥–∞—Ç—å —Å—Ç–æ–ª–±–µ—Ü 'target'.")

    if df['target'].isna().all():
        raise ValueError("–°—Ç–æ–ª–±–µ—Ü 'target' —Å–æ–¥–µ—Ä–∂–∏—Ç —Ç–æ–ª—å–∫–æ NaN –∑–Ω–∞—á–µ–Ω–∏—è, –≤–æ–∑–º–æ–∂–Ω–æ –∏–∑-–∑–∞ –Ω–µ–¥–æ—Å—Ç–∞—Ç–∫–∞ –¥–∞–Ω–Ω—ã—Ö.")

    print("Target column sample:\n", df[['Close', 'target']].head())
    print("Target NaN count:", df['target'].isna().sum())

    initial_rows = len(df)
    df = df.dropna(subset=['target'])
    print(f"After dropping NaN target rows: {len(df)} (removed {initial_rows - len(df)} rows)")

    if df.empty or len(df) == 0:
        raise ValueError("DataFrame –ø—É—Å—Ç –ø–æ—Å–ª–µ —É–¥–∞–ª–µ–Ω–∏—è —Å—Ç—Ä–æ–∫ —Å NaN –≤ 'target'.")

    if len(df) < MIN_DATA_ROWS:
        raise ValueError(f"–ù–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –æ–±—É—á–µ–Ω–∏—è –º–æ–¥–µ–ª–∏. Available rows: {len(df)}, required: {MIN_DATA_ROWS}")

    try:
        X = df[['Open', 'High', 'Low', 'Close', 'Volume']].copy()
        y = (df['target'] > df['Close']).astype(int)
    except Exception as e:
        raise ValueError(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ —Å–æ–∑–¥–∞–Ω–∏–∏ X –∏–ª–∏ y: {str(e)}. –ü—Ä–æ–≤–µ—Ä—å—Ç–µ –≤—ã—Ä–∞–≤–Ω–∏–≤–∞–Ω–∏–µ 'target' –∏ 'Close'.")

    if len(X) != len(y):
        raise ValueError(f"X –∏ y –Ω–µ –≤—ã—Ä–æ–≤–Ω–µ–Ω—ã: X –∏–º–µ–µ—Ç {len(X)} —Å—Ç—Ä–æ–∫, y –∏–º–µ–µ—Ç {len(y)} —Å—Ç—Ä–æ–∫")

    print("Final X shape:", X.shape)
    print("Final y value counts:", y.value_counts().to_dict())

    return X, y

def train_model():
    try:
        X, y = prepare_data()
    except Exception as e:
        print(f"–û—à–∏–±–∫–∞ –ø–æ–¥–≥–æ—Ç–æ–≤–∫–∏ –¥–∞–Ω–Ω—ã—Ö: {e}")
        return

    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, shuffle=False)

    # Define hyperparameter grid for RandomForestClassifier
    param_grid = {
        'n_estimators': [50, 100, 200],
        'max_depth': [None, 10, 20],
        'min_samples_split': [2, 5],
        'min_samples_leaf': [1, 2]
    }

    best_acc = 0.0
    best_model = None
    attempt = 1

    while best_acc < TARGET_ACCURACY and attempt <= MAX_RETRAIN_ATTEMPTS:
        print(f"–ü–æ–ø—ã—Ç–∫–∞ –æ–±—É—á–µ–Ω–∏—è –º–æ–¥–µ–ª–∏ #{attempt}...")
        model = RandomForestClassifier(random_state=42)
        grid_search = GridSearchCV(model, param_grid, cv=3, scoring='accuracy', n_jobs=-1)
        grid_search.fit(X_train, y_train)

        # Get the best model and its accuracy
        best_model = grid_search.best_estimator_
        preds = best_model.predict(X_test)
        acc = accuracy_score(y_test, preds)
        print(f"–ü–æ–ø—ã—Ç–∫–∞ #{attempt} - –õ—É—á—à–∞—è —Ç–æ—á–Ω–æ—Å—Ç—å: {acc:.2f}, –õ—É—á—à–∏–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã: {grid_search.best_params_}")

        if acc > best_acc:
            best_acc = acc
            best_model = grid_search.best_estimator_

        if best_acc >= TARGET_ACCURACY:
            print(f"–î–æ—Å—Ç–∏–≥–Ω—É—Ç–∞ —Ü–µ–ª–µ–≤–∞—è —Ç–æ—á–Ω–æ—Å—Ç—å {best_acc:.2f}. –°–æ—Ö—Ä–∞–Ω—è–µ–º –º–æ–¥–µ–ª—å.")
            break

        attempt += 1
        print(f"–¢–æ—á–Ω–æ—Å—Ç—å {best_acc:.2f} –Ω–∏–∂–µ —Ü–µ–ª–µ–≤–æ–π ({TARGET_ACCURACY}). –ü—Ä–æ–±—É–µ–º —Å–Ω–æ–≤–∞...")

    if best_acc < TARGET_ACCURACY:
        print(f"–ù–µ —É–¥–∞–ª–æ—Å—å –¥–æ—Å—Ç–∏—á—å —Ü–µ–ª–µ–≤–æ–π —Ç–æ—á–Ω–æ—Å—Ç–∏ {TARGET_ACCURACY} –ø–æ—Å–ª–µ {MAX_RETRAIN_ATTEMPTS} –ø–æ–ø—ã—Ç–æ–∫. –ò—Å–ø–æ–ª—å–∑—É–µ–º –ª—É—á—à—É—é –º–æ–¥–µ–ª—å —Å —Ç–æ—á–Ω–æ—Å—Ç—å—é {best_acc:.2f}.")

    # Save the best model
    joblib.dump(best_model, MODEL_PATH)

    # Save accuracy and training info
    with open(ACCURACY_PATH, "w") as f:
        json.dump({"accuracy": best_acc, "last_trained": str(datetime.now()), "best_params": grid_search.best_params_}, f)

    # Generate signal with the best model
    generate_signal(best_model, X.iloc[-1:], X.index[-1])

def generate_signal(model, latest_data, last_index):
    prediction = model.predict(latest_data)[0]
    current_price = latest_data['Close'].iloc[0]
    stop_loss = current_price * (0.99 if prediction == 1 else 1.01)
    take_profit = current_price * (1.015 if prediction == 1 else 0.985)

    signal = {
        "time": str(datetime.now()),
        "price": round(current_price, 5),
        "signal": "BUY" if prediction == 1 else "SELL",
        "stop_loss": round(stop_loss, 5),
        "take_profit": round(take_profit, 5),
    }

    msg = (
        f"üìä Signal: {signal['signal']}\n"
        f"üïí Time: {signal['time']}\n"
        f"üí∞ Price: {signal['price']}\n"
        f"üìâ Stop Loss: {signal['stop_loss']}\n"
        f"üìà Take Profit: {signal['take_profit']}"
    )
    send_telegram_message(msg)

@app.get("/")
async def root():
    if not os.path.exists(MODEL_PATH) or not os.path.exists(ACCURACY_PATH):
        train_model()
    else:
        with open(ACCURACY_PATH, "r") as f:
            data = json.load(f)
        last_trained = datetime.fromisoformat(data["last_trained"])
        if (datetime.now() - last_trained).days >= 1 or data["accuracy"] < TARGET_ACCURACY:
            train_model()
    return {"status": "Bot is running"}

if __name__ == "__main__":
    uvicorn.run(app, host="0.0.0.0", port=int(os.environ.get("PORT", 10000)))
